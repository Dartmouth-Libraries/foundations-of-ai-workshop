{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e9a29-9597-4137-97c0-702f8c4d02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional Rules vs. AI Learning üîÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c735ee62-a9a7-4434-9ac0-2ec650f1e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß TRADITIONAL RULE-BASED APPROACH:\n",
      "----------------------------------------\n",
      "Text: 'Hello, how are you?'\n",
      "Detection: English\n",
      "\n",
      "Text: 'Bonjour, comment allez-vous?'\n",
      "Detection: French\n",
      "\n",
      "Text: 'Guten Tag, wie geht es?'\n",
      "Detection: Unknown\n",
      "\n",
      "‚ùå Problems: Limited vocabulary, can't handle new languages, rigid!\n"
     ]
    }
   ],
   "source": [
    "# TRADITIONAL APPROACH: Rule-based language detection\n",
    "def detect_language_traditional(text):\n",
    "    \"\"\"\n",
    "    Old-school approach: Use fixed rules to detect language.\n",
    "    This is how we programmed before AI!\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Hard-coded rules (rigid, limited)\n",
    "    if 'bonjour' in text_lower or 'merci' in text_lower:\n",
    "        return 'French'\n",
    "    elif 'hola' in text_lower or 'gracias' in text_lower:\n",
    "        return 'Spanish'\n",
    "    elif 'hello' in text_lower or 'thank' in text_lower:\n",
    "        return 'English'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Test our traditional approach\n",
    "test_texts = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Bonjour, comment allez-vous?\",\n",
    "    \"Guten Tag, wie geht es?\",  # German - our rules don't know this!\n",
    "]\n",
    "\n",
    "print(\"üîß TRADITIONAL RULE-BASED APPROACH:\")\n",
    "print(\"-\" * 40)\n",
    "for text in test_texts:\n",
    "    result = detect_language_traditional(text)\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Detection: {result}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚ùå Problems: Limited vocabulary, can't handle new languages, rigid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462e317d-4795-4812-8734-14150d9faa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Dartmouth AI Systems!\n",
      "\n",
      "üß† AI-BASED APPROACH (Learned from Data):\n",
      "----------------------------------------\n",
      "Text: 'Hello, how are you?'\n",
      "AI Detection: en (Confidence: 99.99%)\n",
      "\n",
      "Text: 'Bonjour, comment allez-vous?'\n",
      "AI Detection: fr (Confidence: 95.79%)\n",
      "\n",
      "Text: 'Guten Tag, wie geht es?'\n",
      "AI Detection: de (Confidence: 95.36%)\n",
      "\n",
      "‚úÖ Benefits: Handles any language, learns patterns, flexible!\n"
     ]
    }
   ],
   "source": [
    "# AI APPROACH: Using Dartmouth's language detection API\n",
    "# First, let's set up our connection to real AI models\n",
    "from auth_helpers import load_token_from_file, get_auth_headers\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load our authentication (pre-configured for workshop)\n",
    "jwt_token = load_token_from_file()\n",
    "if jwt_token:\n",
    "    print(\"‚úÖ Connected to Dartmouth AI Systems!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please check with instructor for setup help\")\n",
    "\n",
    "def detect_language_ai(text, jwt_token):\n",
    "    \"\"\"\n",
    "    AI approach: The model has LEARNED from millions of examples.\n",
    "    No rigid rules - it understands patterns!\n",
    "    \"\"\"\n",
    "    url = \"https://api.dartmouth.edu/api/ai/language-detection\"\n",
    "    headers = get_auth_headers(jwt_token)\n",
    "    \n",
    "    # Send text to AI model\n",
    "    files = {'file': ('text.txt', text, 'text/plain')}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, files=files)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['response']['language'], result['response']['score']\n",
    "    except:\n",
    "        return \"Error\", 0\n",
    "\n",
    "print(\"\\nüß† AI-BASED APPROACH (Learned from Data):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for text in test_texts:\n",
    "    if jwt_token:\n",
    "        lang, confidence = detect_language_ai(text, jwt_token)\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(f\"AI Detection: {lang} (Confidence: {confidence:.2%})\")\n",
    "        print()\n",
    "\n",
    "print(\"‚úÖ Benefits: Handles any language, learns patterns, flexible!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f7abd9-e9a3-4e0f-afeb-110045be333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding Models - Input ‚Üí Process ‚Üí Output üîÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64d4df-3cb0-4030-a867-62cea8a07f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_working",
   "language": "python",
   "name": "rag_working"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
